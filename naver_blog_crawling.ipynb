{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, date, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAVER BLOG Crawling\n",
    "- title/url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어 입력\n",
    "query = input(\"검색어 : \")\n",
    "\n",
    "\n",
    "# 조회 기간 설정 : 7일(days에서 수정 가능)\n",
    "# startDate=7일전 날짜, endDate=오늘 날짜\n",
    "date = datetime.now()\n",
    "startDate= (date+timedelta(days=-7)).strftime('%Y-%m-%d')\n",
    "endDate = (datetime.now()).strftime('%Y-%m-%d')\n",
    "\n",
    "print(startDate, endDate)\n",
    "\n",
    "\n",
    "# Chrome driver 환경설정 및 실행\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_argument('headless')\n",
    "driver = webdriver.Chrome(options = options)\n",
    "base_url = f\"https://section.blog.naver.com/Search/Post.naver?pageNo=1&rangeType=WEEK&orderBy=sim&startDate={startDate}&endDate={endDate}&keyword={query}\"\n",
    "driver.get(base_url)\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "# 총 검색 결과\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "search_number = soup.find(class_=\"search_number\")\n",
    "print(\"총 블로그글 개수 : \", search_number.text)\n",
    "\n",
    "\n",
    "# 연관 검색어 \n",
    "sub_keywords_data = soup.select('div.area_keyword > div.list')\n",
    "sub_keywords = []\n",
    "for i in sub_keywords_data: \n",
    "    sub_keywords.append(i.get_text())\n",
    "\n",
    "print(\"연관검색어:\",*sub_keywords)\n",
    "\n",
    "\n",
    "# blog url/title 가져오기\n",
    "total_num = search_number.text.replace(\"건\",'').replace(\",\",'')\n",
    "total_num = int(total_num)\n",
    "page_num = 1\n",
    "end_page=total_num//7+1\n",
    "end_page\n",
    "contents_num = 7\n",
    "\n",
    "blog_title_lst = []\n",
    "blog_url_lst = []\n",
    "\n",
    "while contents_num == 7 : \n",
    "    search_url = f\"https://section.blog.naver.com/Search/Post.naver?pageNo={page_num}&rangeType=WEEK&orderBy=sim&startDate={startDate}&endDate={endDate}&keyword={query}\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    posts_data = soup.select('div.info_post > div.desc > a.desc_inner')\n",
    "    \n",
    "    # 블로그 제목, url 가져오기\n",
    "    posts_data = soup.select('div.info_post > div.desc > a.desc_inner')\n",
    "\n",
    "    for post in posts_data :\n",
    "        title=post.get_text().replace('\\n','').strip()\n",
    "        href=post.attrs['href']\n",
    "        blog_title_lst.append(title)\n",
    "        blog_url_lst.append(href)\n",
    "    \n",
    "    page_num +=1\n",
    "    contents_num = len(posts_data)\n",
    "\n",
    "print(blog_title_lst)\n",
    "print(blog_url_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인\n",
    "print(len(blog_title_lst),len(blog_url_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"title\":blog_title_lst, \"url\":blog_url_lst})\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- blog 본문 가져오기(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구로디지털단지역 맛집 프리미엄 부위가 일품 [참숯구이 육향]\n",
      "19시간 전\n",
      "['누구라도 특별한 날이 다가오면뭐 할지 고민할 것 같은데요.특히나 어른을 모시고 어딘가에가야 하는 경우 더 그렇지 않나 싶어요.부모님과 친한 편인데도 불구하고어버이날 무엇을 준비하면 좋을지쉽사리 결정 내리지 못했어요!다행히 이번엔 구로디지털단지역 맛집에서제 주도 하에 가족이 모여 식사를 했는데맛도 그렇고 친절함 등 전반적으로만족스러워서 뿌듯한 미리 어버이날기념으로 먹고왔어요!', '저희와 같은 생각인지 많이들 외식을하는 날이라 저는 미리 예약을 했는데신의 한 수였어요.평이 좋은 여느 음식점이 보통 그런데여기도 식사 시간대에는 손님이꽤 몰리는 모습이었거든요.', '그래도 복잡한 분위기는 아니라부모님 모시고 가기에 무리는없었어요', '메뉴도 프리미엄 등급 토마호크와한돈 꽃목살, 한돈 숄더랙, 그리고우대갈비까지 아무 곳에서나맛볼 수 없는 귀한 부위 위주로준비되어 있으니 특별한 날에방문하기 좋은 곳이었어요.', '메뉴는 부모님이 드시고 싶어하시는걸로 선택을 해서 주문했어요!결론적으로는 잘했다고 봅니다.쉽게 접하기 어려운 부위이기도 하고맛도 굉장히 훌륭했으니까요.그렇게 주문하고 기다리다 보니기본 반찬이 테이블 위로하나 둘 올라오기 시작했어요.이건 무를 적당히 얇게 썰어서양념한 건데 고기를 먹다 보면 어느새슬쩍 스며드는 느끼함을 잡아줄 때큰 역할을 해주었습니다.', '', '젓갈은 밥이랑 먹을 때도 맛있는데의외로 고기랑도 잘 어울리더라고요!식당에서 식사할 때마다 젓갈을 주면그렇게 반가운데요. 이날도마찬가지였어요. 쌈을 싸먹을 때도잘 어울린답니다.약간 흐물거리는 게 나오는 곳도있는데 구로디지털단지역 맛집은기본찬 수준도 훌륭해서 쫄깃하고감칠맛까지 났어요.', '고기 좀 좋아한다, 먹을 줄 안다~이런 분이면 아실 거에요.숯이 얼마나 중요한지를 말이에요.좋지 않은 걸 쓰면 일단 건강에도좋지 않고 향이 베이지 않아 불맛을입히는 데에도 지장이 생기는불상사가 생기죠.그래서 항상 어떤 숯이 나오는지신경 써서 살펴보는데요.여긴 이렇게 참숯이 나와서 먹기전부터 기대가 됐어요', '', '', '주문한 고기가 나왔는데 육질이좋은게 느껴지는게 선홍빛이선명하게 보이고 마블링도 너무과하지 않게 있었어요!직원분이 고기를 가져다 주시면서사진도 먼저 찍을 수 있게 기다려주시는데 서비스도 만족했어요', '고기를 잘 못 굽는 편은 아닌데,고기 자체가 두껍기도 하고특별한 날에 부모님과 함께방문한 거니까 이왕이면구워주는 곳이 좋겠다 싶었어요.그래서 여기로 정한 것이기도 해요.', '예상대로 구로디지털단지역 맛집 직원분이가져오셔서 부위 설명과 더불어굽는 과정, 어떻게 먹어야 더 맛있는지 등을친절히 알려주셨고 덕분에 더욱 즐거운식사가 되었던 것 같아요.', '엄마, 아빠가 어릴 때부터 항상 뼈에 붙은고기가 제일 맛있는 거라고 말씀하셨던기억이 있는데요. 해당 부위를 그것도직접 알아본 곳에서 맛보실 수 있도록하니까 기분이 좋더라고요.살코기 부분이 살짝 더 많아 보여서혹시 퍽퍽하지는 않을까 했는데지방층이 적당히 섞여서 씹을 때마다육즙까지 팡팡 터지는 게 일품이었습니다.', '너무 자주 뒤집어도 안 되고 두툼한상태로 그냥 둬도 맛없어지는 거아는 분은 아실 텐데요.전문가가 그런 거 다 고려해서구워주시니까 맛있게 먹기만 하면 끝!이제 먹어도 된다고 말씀하신 순간부터윤기가 흐르는 게 눈에 보이니침이 저절로 꼴깍 넘어가더라고요 ㅎㅎㅎ', '고기 본연의 맛을 느끼려거든 소금만살짝 찍는 거라고 텔레비전 어떤프로그램에서 봤었거든요.그 이후로 저도 그렇게 하고 있는데멜젓이 있는데 한 가지 방식만고집하기는 너무 아쉬울듯했어요.살짝 꼬릿하면서 짭조름한 특유의매력이 담백하고 고소한 고기와정말 잘 어울리잖아요.ㅎㅎㅎ', '구로디지털단지역 맛집이라고 알려진곳인 만큼 사장님께서 맛잘알이신 건지멜젓도 그냥 주지 않으시고 청양고추까지작게 썰어서 넣어주시는 센스를 발휘하셨어요.덕분에 개운한 맛까지 더할 수 있었습니다.', '나물, 채소를 좋아하시는 엄마는 고기를먹을 때 절대 그냥 드시는 법이 없는데이날의 베스트 곁들임 조합은 이거였어요.명이나물에 살짝 와사비를 올린 뒤김치를 더해 한 입 가득 넣고 먹는 거에요.', '하도 칭찬하시기에 저도 따라 해봤는데그 맛이 아직도 입 안에서 맴도는 것같을 정도로 훌륭했어요.', '', '이것이 구로디지털단지역 맛집의또 다른 대표 메뉴 우대갈비입니다.그냥 보기에도 마블링이 환상적이었고갈비 중 가장 맛이 좋다는 설명까지더해지니 불판 위에 올라가기 전부터기대가 되었습니다.', '소고기라서 너무 오래 구우면 안 되고그렇다고 너무 성급히 먹었다가는깊은 맛이 반감될 수 있다고 하니까그 부분을 감안해 맛보면 좋을듯합니다.보니까 굽는 방법도 있더라고요.기름과 버터를 이용하는데요.이렇게 해서 앞, 뒤를 바삭한 느낌으로익힌 뒤에 적당한 두께로 잘라줍니다.', '숄더랙과 마찬가지로 살코기와지방층이 적절하게 섞인 모습이었어요.그래서 씹었을 때 담백한 살코기의풍미와 부드러운 육즙의 매력모두가 느껴졌습니다.', '부위도 부위지만 구로디지털단지역 맛집참숯구이육향에서 좋은 고기만취급하기에 가능한 부분이아닐까 싶어요.', '너무 얇게 썰지 않아서 씹는 재미도충분히 누릴 수 있게 해주셨어요.우대갈비라는 부위가 워낙 맛있다 보니언젠가부터 엄청 인기가 높아졌다는데저는 이제서야 이 매력에 빠졌다는게조금 억울하다는 생각도 들었어요.', '', '그래도 부모님이 맛있게 드시는 걸보니 뿌듯하기도 하고 저도 너무맛있게 먹어서 후회없는 선택이였어요!가게 분위기나 고기의 퀄리티까지뭐 하나 빠지는 것 없는구로디지털단지역 맛집!!아묻따 방문 추천해용 ㅎㅎ', '제가 방문한 참숯구이 육향구로디지털단지점은 구디역3번 출구에서 나오시면 7분 정도거리에 있고 다른 대중교통으로도방문이 가능해요!주차장이나 예약도 가능해서참고하시면 좋을 것 같아요!시간은 오전 11시부터오후 10시까지 장사를 하시고오후 3시부터 4시 40분까지브레이크 타임입니다!!', '#구로디지털단지맛집 #구로디지털단지역맛집 #구디맛집#참숯구이육향 #육향 #우대갈비 #숄더랙', '']\n"
     ]
    }
   ],
   "source": [
    "# Chrome driver 실행\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_argument('headless')\n",
    "driver = webdriver.Chrome(options = options)\n",
    "\n",
    "\n",
    "# 해당 blog 불러오기 \n",
    "url = blog_url_lst[0]\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "# iframe 접근 \n",
    "driver.switch_to.frame('mainFrame')\n",
    "\n",
    "\n",
    "# 제목 가져오기\n",
    "overlays_title = \".se-module.se-module-text.se-title-text\"\n",
    "html_title = driver.find_element(By.CSS_SELECTOR, overlays_title)\n",
    "title = html_title.text\n",
    "print(title)\n",
    "\n",
    "\n",
    "# 포스팅 날짜 가져오기\n",
    "overlays_publishDate = \".se_publishDate.pcol2\"\n",
    "html_publishDate = driver.find_element(By.CSS_SELECTOR, overlays_publishDate)\n",
    "date = html_publishDate.text\n",
    "print(date)\n",
    "\n",
    "# 본문 가져오기 \n",
    "overlays_content = \".se-component.se-text.se-l-default\"\n",
    "html_content = driver.find_elements(By.CSS_SELECTOR, overlays_content)\n",
    "contents_lst = []\n",
    "for content in html_content : \n",
    "    contents_lst.append(content.text.replace('\\n',''))\n",
    "    \n",
    "\n",
    "print(contents_lst)\n",
    "\n",
    "# 해시태그 가져오기 \n",
    "\n",
    "# title = html_title.text \n",
    "# title\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- blog 본문 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome driver 실행\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_argument('headless')\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "crawling_blog_data = []\n",
    "\n",
    "\n",
    "# blog 본문 가져오기 \n",
    "for i in range(0, len(blog_url_lst)) :    \n",
    "    url = str(blog_url_lst[i])\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # 본문 크롤링 예외 처리 \n",
    "    try :\n",
    "        # iframe 접근 \n",
    "        driver.switch_to.frame('mainFrame')\n",
    "\n",
    "        \n",
    "        # 제목 가져오기\n",
    "        overlays_title = \".se-module.se-module-text.se-title-text\"\n",
    "        html_title = driver.find_element(By.CSS_SELECTOR, overlays_title)\n",
    "        title = html_title.text\n",
    "\n",
    "        \n",
    "        # 작성 날짜 가져오기\n",
    "        overlays_publishDate = \".se_publishDate.pcol2\"\n",
    "        html_publishDate = driver.find_element(By.CSS_SELECTOR, overlays_publishDate)\n",
    "        date = html_publishDate.text\n",
    "\n",
    "        \n",
    "        # 본문 가져오기\n",
    "        overlays_content = \".se-component.se-text.se-l-default\"\n",
    "        html_content = driver.find_elements(By.CSS_SELECTOR, overlays_content)\n",
    "        contents_lst = []\n",
    "        for content in html_content : \n",
    "            contents_lst.append(content.text.replace('\\n',''))\n",
    "        content_str = ''.join(contents_lst)\n",
    "\n",
    "        \n",
    "        # 크롤링한 내용 담기 \n",
    "        crawling_blog_data.append({\"title\":title, \"date\":date, \"content\":content_str})\n",
    "        \n",
    "        # driver 종료 \n",
    "        driver.close\n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "    # 에러 발생시 다음 블로그로 이동\n",
    "    except : \n",
    "        print(\"error\",i,title)\n",
    "        driver.close()\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
