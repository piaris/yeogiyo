{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, date, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAVER BLOG Crawling\n",
    "- title/url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어 입력\n",
    "query = input(\"검색어 : \")\n",
    "\n",
    "\n",
    "# 조회 기간 설정 : 7일(days에서 수정 가능)\n",
    "# startDate=7일전 날짜, endDate=오늘 날짜\n",
    "date = datetime.now()\n",
    "startDate= (date+timedelta(days=-7)).strftime('%Y-%m-%d')\n",
    "endDate = (datetime.now()).strftime('%Y-%m-%d')\n",
    "\n",
    "print(startDate, endDate)\n",
    "\n",
    "\n",
    "# Chrome driver 환경설정 및 실행\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_argument('headless')\n",
    "driver = webdriver.Chrome(options = options)\n",
    "base_url = f\"https://section.blog.naver.com/Search/Post.naver?pageNo=1&rangeType=WEEK&orderBy=sim&startDate={startDate}&endDate={endDate}&keyword={query}\"\n",
    "driver.get(base_url)\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "# 총 검색 결과\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "search_number = soup.find(class_=\"search_number\")\n",
    "print(\"총 블로그글 개수 : \", search_number.text)\n",
    "\n",
    "\n",
    "# 연관 검색어 \n",
    "sub_keywords_data = soup.select('div.area_keyword > div.list')\n",
    "sub_keywords = []\n",
    "for i in sub_keywords_data: \n",
    "    sub_keywords.append(i.get_text())\n",
    "\n",
    "print(\"연관검색어:\",*sub_keywords)\n",
    "\n",
    "\n",
    "# blog url/title 가져오기\n",
    "total_num = search_number.text.replace(\"건\",'').replace(\",\",'')\n",
    "total_num = int(total_num)\n",
    "page_num = 1\n",
    "end_page=total_num//7+1\n",
    "contents_num = 7\n",
    "\n",
    "blog_title_lst = []\n",
    "blog_url_lst = []\n",
    "\n",
    "while contents_num == 7 : \n",
    "    search_url = f\"https://section.blog.naver.com/Search/Post.naver?pageNo={page_num}&rangeType=WEEK&orderBy=sim&startDate={startDate}&endDate={endDate}&keyword={query}\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # 블로그 제목, url, 포스팅 날짜 가져오기\n",
    "    posts_data = soup.select('div.info_post > div.desc > a.desc_inner')\n",
    "\n",
    "    for post in posts_data :\n",
    "        title=post.get_text().replace('\\n','').strip()\n",
    "        href=post.attrs['href']\n",
    "        blog_title_lst.append(title)\n",
    "        blog_url_lst.append(href)\n",
    "    \n",
    "    page_num +=1\n",
    "    contents_num = len(posts_data)\n",
    "\n",
    "print(blog_title_lst)\n",
    "print(blog_url_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인\n",
    "print(len(blog_title_lst),len(blog_url_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- blog 본문 가져오기(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome driver 실행\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_argument('headless')\n",
    "driver = webdriver.Chrome(options = options)\n",
    "\n",
    "\n",
    "# 해당 blog 불러오기 \n",
    "url = blog_url_lst[0]\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "# iframe 접근 \n",
    "driver.switch_to.frame('mainFrame')\n",
    "\n",
    "\n",
    "# 제목 가져오기\n",
    "overlays_title = \".se-module.se-module-text.se-title-text\"\n",
    "html_title = driver.find_element(By.CSS_SELECTOR, overlays_title)\n",
    "title = html_title.text\n",
    "print(title)\n",
    "\n",
    "\n",
    "# 포스팅 날짜 가져오기\n",
    "overlays_publishDate = \".se_publishDate.pcol2\"\n",
    "html_publishDate = driver.find_element(By.CSS_SELECTOR, overlays_publishDate)\n",
    "date = html_publishDate.text\n",
    "print(date)\n",
    "\n",
    "# 본문 가져오기 \n",
    "overlays_content = \".se-component.se-text.se-l-default\"\n",
    "html_content = driver.find_elements(By.CSS_SELECTOR, overlays_content)\n",
    "contents_lst = []\n",
    "for content in html_content : \n",
    "    contents_lst.append(content.text.replace('\\n',''))\n",
    "    \n",
    "\n",
    "print(contents_lst)\n",
    "\n",
    "# 해시태그 가져오기 \n",
    "\n",
    "# title = html_title.text \n",
    "# title\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- blog 본문 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome driver 실행\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_argument('headless')\n",
    "driver = webdriver.Chrome(options = options)\n",
    "\n",
    "crawling_blog_data = []\n",
    "\n",
    "\n",
    "# blog 본문 가져오기 \n",
    "for i in range(len(blog_url_lst)) :    \n",
    "    url = str(blog_url_lst[i])\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # 본문 크롤링 예외 처리 \n",
    "    try :\n",
    "        # iframe 접근 \n",
    "        driver.switch_to.frame('mainFrame')\n",
    "\n",
    "        \n",
    "        # 제목 가져오기\n",
    "        overlays_title = \".se-module.se-module-text.se-title-text\"\n",
    "        html_title = driver.find_element(By.CSS_SELECTOR, overlays_title)\n",
    "        title = html_title.text\n",
    "\n",
    "        \n",
    "        # 작성 날짜 가져오기\n",
    "        overlays_publishDate = \".se_publishDate.pcol2\"\n",
    "        html_publishDate = driver.find_element(By.CSS_SELECTOR, overlays_publishDate)\n",
    "        date = html_publishDate.text\n",
    "\n",
    "        \n",
    "        # 본문 가져오기\n",
    "        overlays_content = \".se-component.se-text.se-l-default\"\n",
    "        html_content = driver.find_elements(By.CSS_SELECTOR, overlays_content)\n",
    "        contents_lst = []\n",
    "        for content in html_content : \n",
    "            contents_lst.append(content.text.replace('\\n',''))\n",
    "        content_str = ''.join(contents_lst)\n",
    "\n",
    "        \n",
    "        # 크롤링한 내용 담기 \n",
    "        crawling_blog_data.append({\"title\":title, \"date\":date, \"content\":content_str})\n",
    "        \n",
    "        # driver 종료 \n",
    "        driver.close\n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "    # 에러 발생시 다음 블로그로 이동\n",
    "    except : \n",
    "        print(\"error\",i,title)\n",
    "        driver.close()\n",
    "        time.sleep(1)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crawling_blog_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(crawling_blog_data)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"{query}_{datetime.now().strftime('%Y%m%d')}.xlsx\"\n",
    "df.to_excel(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(crawling_blog_data).sort_values(by=date, axis=0, ascending=False, inplace=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
